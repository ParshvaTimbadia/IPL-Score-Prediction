# -*- coding: utf-8 -*-
"""IPL Score Prediction .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ps-u1lC-WT_Rb4qW9RK_ZzYE2-VmF9cj
"""

#Importing the libraries. 
import pandas as pd
import pickle
from datetime import datetime
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
import numpy as np
from sklearn.linear_model import Lasso

#Let's import the dataset.

dataset = pd.read_csv("ipl.csv")

dataset.head()

dataset.shape

dataset.describe()

#Let's start cleaning the data

#First we will drop the colums which we are not going to consider for our model prediction.
dataset.drop(labels=["mid", "venue","batsman","bowler", "striker", "non-striker"], axis=1, inplace=True)

dataset.head()

#Listing all the teams present in the dataset
dataset["bat_team"].unique()

#During the league some of the teams get relegated each year so we will only create prediciton for the popular teams. 

popular_teams = ['Kolkata Knight Riders', 'Chennai Super Kings', 'Rajasthan Royals',
       'Mumbai Indians', 'Kings XI Punjab',
       'Royal Challengers Bangalore', 'Delhi Daredevils', 'Pune Warriors', 'Sunrisers Hyderabad']

#Now we will filter out the dataset based on the consistent teams only.

dataset = dataset[dataset["bat_team"].isin(popular_teams) & dataset["bowl_team"].isin(popular_teams) ]

#Checking if the teams were dropped or not.
dataset["bat_team"].unique()

#removing the first 5 overs since we atleast need to have 5 overs data to make a prediction.
dataset = dataset[dataset['overs']>=5.0]

#Now if we check our dataset we will find that the dataset also includes dates, so we will consider that in the date time format.
# https://stackoverflow.com/questions/57094792/how-to-strip-date-time-in-python
dataset['date'] = dataset['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))
dataset.head

#Now data preprocessing on textual data
#Converted Categorical data to numerical
ndataset = pd.get_dummies(data=dataset, columns=["bat_team", "bowl_team"])
ndataset.head()

# Rearranging the columns
ndataset = ndataset[['date', 'bat_team_Chennai Super Kings', 'bat_team_Delhi Daredevils', 'bat_team_Kings XI Punjab',
              'bat_team_Kolkata Knight Riders', 'bat_team_Mumbai Indians', 'bat_team_Rajasthan Royals',
              'bat_team_Royal Challengers Bangalore', 'bat_team_Sunrisers Hyderabad',
              'bowl_team_Chennai Super Kings', 'bowl_team_Delhi Daredevils', 'bowl_team_Kings XI Punjab',
              'bowl_team_Kolkata Knight Riders', 'bowl_team_Mumbai Indians', 'bowl_team_Rajasthan Royals',
              'bowl_team_Royal Challengers Bangalore', 'bowl_team_Sunrisers Hyderabad',
              'overs', 'runs', 'wickets', 'runs_last_5', 'wickets_last_5', 'total']]

# Splitting the data into train and test set where all the years before 2017 will be training set
X_train = ndataset.drop(labels='total', axis=1)[ndataset['date'].dt.year <= 2016]
X_test = ndataset.drop(labels='total', axis=1)[ndataset['date'].dt.year >= 2017]

#Spliting the data into train and test
y_train = ndataset[ndataset['date'].dt.year <= 2016]['total'].values
y_test = ndataset[ndataset['date'].dt.year >= 2017]['total'].values

# Removing the 'date' column
X_train.drop(labels='date', axis=True, inplace=True)
X_test.drop(labels='date', axis=True, inplace=True)

#Implementing Ridge Regression
ridge=Ridge()
parameters={'alpha':[1e-20,1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,50,60,70,80,90,100]}
ridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=5)
ridge_regressor.fit(X_train,y_train)

print(ridge_regressor.best_params_)
print(ridge_regressor.best_score_)

prediction1=ridge_regressor.predict(X_test)

#Let's check for the prediction
import seaborn as sns
sns.distplot(y_test-prediction1)

print('MAE:', metrics.mean_absolute_error(y_test, prediction1))
print('MSE:', metrics.mean_squared_error(y_test, prediction1))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction1)))

#Applying Lasso regression model
lasso=Lasso()
parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40]}
lasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)

lasso_regressor.fit(X_train,y_train)
print(lasso_regressor.best_params_)
print(lasso_regressor.best_score_)

prediction2=lasso_regressor.predict(X_test)

sns.distplot(y_test-prediction2)

print('MAE:', metrics.mean_absolute_error(y_test, prediction2))
print('MSE:', metrics.mean_squared_error(y_test, prediction2))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction2)))

filename = 'score-predict-lasso-model.pkl'
pickle.dump(lasso_regressor, open(filename, 'wb'))
